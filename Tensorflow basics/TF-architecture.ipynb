{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In depth architecture and structure for basic Neural Networks\n",
    "\n",
    "In other notebooks of this section, we have taken a look at how neural networks help us with different regression and classification problems. I would like to go a bit in depth to see exactly in this structure we have built, to understand better how the networks evolve when we train it and comprehend better what goes behind each step of the training."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalling from our TF-regression notebook, the structure of a basic NN could look like this :\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "As we can see, each layer has a certain amount of neurons that is fully interconnected with the neurons from previous and posterior layers.\n",
    "\n",
    "When in our notebooks we store a model we have created, we are saving this information about out model:\n",
    "\n",
    "* The weight values\n",
    "* The model's architecture\n",
    "* The model's training configuration (what you pass to the .compile() method)\n",
    "* The optimizer and its state, if any (this enables you to restart training where you left off)\n",
    "\n",
    "Let's go through, one by one, the information we save to understand better the work we are saving here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model's architecture.\n",
    "\n",
    "It is not the first time we plot our model. One part of information we save into the keras file is the number of layers, output shape of each layer and the number of parameters on each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start first for bringing back some example that we have worked with. I would bring back the last model saved from regression, but to see better how the propagation works, we will recreate some data and create a model with just 3 layers and a few neurons to see how the process goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate some data from TF-regression for our experiment.\n",
    "import numpy as np\n",
    "\n",
    "def OurLinearCorrelation(x):\n",
    "    '''Function to create linear correlation on a dependant variable\n",
    "    '''\n",
    "    return ((2*x)+3)\n",
    "\n",
    "x_large = np.arange(-100,50,2)\n",
    "y_large = OurLinearCorrelation(x_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_large[:16]\n",
    "x_test = x_large[:16]\n",
    "y_train = y_large[16:]\n",
    "x_train = x_large[16:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the min-max values to normalize the inputs later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, -70, 99, -137)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max(),x_test.max(),y_train.max(),y_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-68, -100, -133, -197)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min(),x_test.min(),y_train.min(),y_test.min(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(x_train,x_test,y_train,y_test):\n",
    "    x_max = x_train.max() if abs(x_train.max()) > abs(x_test.max()) else x_test.max()\n",
    "    y_max = y_train.max() if abs(y_train.max()) > abs(y_test.max()) else y_test.max()\n",
    "    x_min = x_train.min() if abs(x_train.min()) < abs(x_test.max()) else x_test.min()\n",
    "    y_min = y_train.min() if abs(y_train.min()) < abs(y_test.max()) else y_test.min()\n",
    "    x_train_mm = (x_train - x_train.min())/(x_train.max() - x_train.min())\n",
    "    x_test_mm = (x_test - x_test.min())/(x_test.max() - x_test.min())\n",
    "    y_train_mm = (y_train - y_train.min())/(y_train.max() - y_train.min())    \n",
    "    y_test_mm = (y_test - y_test.min())/(y_test.max() - y_test.min())\n",
    "    return x_train_mm,x_test_mm,y_train_mm,y_test_mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mm,x_test_mm,y_train_mm,y_test_mm = MinMaxScaler(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.01724138, 0.03448276, 0.05172414, 0.06896552,\n",
       "        0.0862069 , 0.10344828, 0.12068966, 0.13793103, 0.15517241,\n",
       "        0.17241379, 0.18965517, 0.20689655, 0.22413793, 0.24137931,\n",
       "        0.25862069, 0.27586207, 0.29310345, 0.31034483, 0.32758621,\n",
       "        0.34482759, 0.36206897, 0.37931034, 0.39655172, 0.4137931 ,\n",
       "        0.43103448, 0.44827586, 0.46551724, 0.48275862, 0.5       ,\n",
       "        0.51724138, 0.53448276, 0.55172414, 0.56896552, 0.5862069 ,\n",
       "        0.60344828, 0.62068966, 0.63793103, 0.65517241, 0.67241379,\n",
       "        0.68965517, 0.70689655, 0.72413793, 0.74137931, 0.75862069,\n",
       "        0.77586207, 0.79310345, 0.81034483, 0.82758621, 0.84482759,\n",
       "        0.86206897, 0.87931034, 0.89655172, 0.9137931 , 0.93103448,\n",
       "        0.94827586, 0.96551724, 0.98275862, 1.        ]),\n",
       " array([0.        , 0.01724138, 0.03448276, 0.05172414, 0.06896552,\n",
       "        0.0862069 , 0.10344828, 0.12068966, 0.13793103, 0.15517241,\n",
       "        0.17241379, 0.18965517, 0.20689655, 0.22413793, 0.24137931,\n",
       "        0.25862069, 0.27586207, 0.29310345, 0.31034483, 0.32758621,\n",
       "        0.34482759, 0.36206897, 0.37931034, 0.39655172, 0.4137931 ,\n",
       "        0.43103448, 0.44827586, 0.46551724, 0.48275862, 0.5       ,\n",
       "        0.51724138, 0.53448276, 0.55172414, 0.56896552, 0.5862069 ,\n",
       "        0.60344828, 0.62068966, 0.63793103, 0.65517241, 0.67241379,\n",
       "        0.68965517, 0.70689655, 0.72413793, 0.74137931, 0.75862069,\n",
       "        0.77586207, 0.79310345, 0.81034483, 0.82758621, 0.84482759,\n",
       "        0.86206897, 0.87931034, 0.89655172, 0.9137931 , 0.93103448,\n",
       "        0.94827586, 0.96551724, 0.98275862, 1.        ]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mm,y_train_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our input normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 10:10:31.352582: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-23 10:10:31.481041: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-23 10:10:31.603296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-23 10:10:31.742246: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-23 10:10:31.743128: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-23 10:10:32.186651: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-23 10:10:33.888847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintWeightsCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print(f\"Batch {batch + 1}:\")\n",
    "        for layer in self.model.layers:\n",
    "            weights = layer.get_weights()  # Get weights and biases of the layer\n",
    "            if weights:  # Some layers may not have weights (e.g., Dropout)\n",
    "                print(f\"Weights of {layer.name}: {weights[0]}\")  # Weight matrix\n",
    "                print(f\"Biases of {layer.name}: {weights[1]}\")  # Bias vector\n",
    "                print(f\"output of layer of {layer.name}: {layer.output}\") # output vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_layer = model_1.get_layer(index=0)\n",
    "#first_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Batch 1:\n",
      "Weights of dense_3: [[ 1.02756    -0.15965983]]\n",
      "Biases of dense_3: [-1.7091781e-05 -4.9162980e-05]\n",
      "output of layer of dense_3: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "Weights of dense_4: [[ 0.9779176  -1.0172834 ]\n",
      " [-0.07847307 -0.02070478]]\n",
      "Biases of dense_4: [0.00026433 0.00038198]\n",
      "output of layer of dense_4: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "Weights of dense_5: [[-0.05142435]\n",
      " [-0.8752576 ]]\n",
      "Biases of dense_5: [-0.000625]\n",
      "output of layer of dense_5: <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 718ms/step - loss: 63.6348 - mae: 63.6348Batch 2:\n",
      "Weights of dense_3: [[ 1.2634093  -0.15343934]]\n",
      "Biases of dense_3: [-1.5728254e-03 -9.0195288e-05]\n",
      "output of layer of dense_3: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "Weights of dense_4: [[ 0.9630828  -1.269776  ]\n",
      " [-0.07616808  0.01852682]]\n",
      "Biases of dense_4: [0.00035956 0.00200283]\n",
      "output of layer of dense_4: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "Weights of dense_5: [[ 0.23420024]\n",
      " [-1.1677942 ]]\n",
      "Biases of dense_5: [-0.00247685]\n",
      "output of layer of dense_5: <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 53.8178 - mae: 53.8178 \n",
      "Epoch 2/5\n",
      "Batch 1:\n",
      "Weights of dense_3: [[ 0.77011126 -0.1420412 ]]\n",
      "Biases of dense_3: [ 0.00590139 -0.00026289]\n",
      "output of layer of dense_3: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "Weights of dense_4: [[ 0.87764275 -0.84374565]\n",
      " [-0.06579179 -0.03321255]]\n",
      "Biases of dense_4: [ 0.00138419 -0.00310627]\n",
      "output of layer of dense_4: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "Weights of dense_5: [[-0.12052113]\n",
      " [-0.7037296 ]]\n",
      "Biases of dense_5: [0.00189815]\n",
      "output of layer of dense_5: <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 6.0644 - mae: 6.0644Batch 2:\n",
      "Weights of dense_3: [[ 0.9078341 -0.1332071]]\n",
      "Biases of dense_3: [ 0.00463622 -0.00034405]\n",
      "output of layer of dense_3: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "Weights of dense_4: [[ 0.8514502  -0.99668527]\n",
      " [-0.06096052 -0.00500249]]\n",
      "Biases of dense_4: [ 0.00169665 -0.00128179]\n",
      "output of layer of dense_4: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "Weights of dense_5: [[ 0.07284828]\n",
      " [-0.88575906]]\n",
      "Biases of dense_5: [-0.00069444]\n",
      "output of layer of dense_5: <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 18.0003 - mae: 18.0003\n",
      "Epoch 3/5\n",
      "Batch 1:\n",
      "Weights of dense_3: [[ 1.211367   -0.13321027]]\n",
      "Biases of dense_3: [ 0.00404568 -0.00034404]\n",
      "output of layer of dense_3: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "Weights of dense_4: [[ 0.87269557 -1.255007  ]\n",
      " [-0.06407788  0.03290141]]\n",
      "Biases of dense_4: [ 0.00165112 -0.00072819]\n",
      "output of layer of dense_4: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "Weights of dense_5: [[ 0.32377183]\n",
      " [-1.1762164 ]]\n",
      "Biases of dense_5: [-0.00131944]\n",
      "output of layer of dense_5: <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 36.5070 - mae: 36.5070Batch 2:\n",
      "Weights of dense_3: [[ 0.7645234  -0.11810663]]\n",
      "Biases of dense_3: [ 0.01381632 -0.0006743 ]\n",
      "output of layer of dense_3: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "Weights of dense_4: [[ 0.77305335 -0.8930212 ]\n",
      " [-0.05312036 -0.00690572]]\n",
      "Biases of dense_4: [ 0.00344985 -0.00726272]\n",
      "output of layer of dense_4: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "Weights of dense_5: [[ 0.05303642]\n",
      " [-0.7888729 ]]\n",
      "Biases of dense_5: [0.00423611]\n",
      "output of layer of dense_5: <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 26.9491 - mae: 26.9491 \n",
      "Epoch 4/5\n",
      "Batch 1:\n",
      "Weights of dense_3: [[ 1.0040089  -0.11726161]]\n",
      "Biases of dense_3: [ 0.01335039 -0.00067594]\n",
      "output of layer of dense_3: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "Weights of dense_4: [[ 0.7860788  -1.0867641 ]\n",
      " [-0.05513263  0.02302517]]\n",
      "Biases of dense_4: [ 0.00341671 -0.00676968]\n",
      "output of layer of dense_4: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "Weights of dense_5: [[ 0.24490735]\n",
      " [-1.0079274 ]]\n",
      "Biases of dense_5: [0.00361111]\n",
      "output of layer of dense_5: <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 45.7645 - mae: 45.7645Batch 2:\n",
      "Weights of dense_3: [[ 1.3617578  -0.12745886]]\n",
      "Biases of dense_3: [ 0.0119194  -0.00063515]\n",
      "output of layer of dense_3: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "Weights of dense_4: [[ 0.85437775 -1.3678514 ]\n",
      " [-0.06310973  0.0558553 ]]\n",
      "Biases of dense_4: [ 0.00314459 -0.00564976]\n",
      "output of layer of dense_4: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "Weights of dense_5: [[ 0.46591824]\n",
      " [-1.3117429 ]]\n",
      "Biases of dense_5: [0.0025]\n",
      "output of layer of dense_5: <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 37.6563 - mae: 37.6563 \n",
      "Epoch 5/5\n",
      "Batch 1:\n",
      "Weights of dense_3: [[ 0.6602092 -0.0946039]]\n",
      "Biases of dense_3: [ 0.01603003 -0.00082766]\n",
      "output of layer of dense_3: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "Weights of dense_4: [[ 0.6513585  -0.79627234]\n",
      " [-0.04410695  0.00235503]]\n",
      "Biases of dense_4: [ 0.00401818 -0.00810927]\n",
      "output of layer of dense_4: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "Weights of dense_5: [[ 0.09106359]\n",
      " [-0.7134477 ]]\n",
      "Biases of dense_5: [0.004375]\n",
      "output of layer of dense_5: <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 32.5082 - mae: 32.5082Batch 2:\n",
      "Weights of dense_3: [[ 0.83727926 -0.09621164]]\n",
      "Biases of dense_3: [ 0.01440341 -0.00081289]\n",
      "output of layer of dense_3: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_5>\n",
      "Weights of dense_4: [[ 0.6683222  -0.92917633]\n",
      " [-0.04653809  0.02140207]]\n",
      "Biases of dense_4: [ 0.00378209 -0.0062596 ]\n",
      "output of layer of dense_4: <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_6>\n",
      "Weights of dense_5: [[ 0.21356845]\n",
      " [-0.8618224 ]]\n",
      "Biases of dense_5: [0.00178241]\n",
      "output of layer of dense_5: <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_7>\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.0039 - mae: 36.0039 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2267fff4c0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple NN for regression\n",
    "\n",
    "# Set random seed for weight initialization.\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "# 1. Create our model\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(2),\n",
    "  tf.keras.layers.Dense(2),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "\n",
    "model_1.fit(tf.expand_dims(x_train, axis=-1), y_train, epochs=5,verbose=1,callbacks=[PrintWeightsCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Dense name=dense, built=True>,\n",
       " <Dense name=dense_1, built=True>,\n",
       " <Dense name=dense_2, built=True>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m4\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> (64.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15\u001b[0m (64.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> (52.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13\u001b[0m (52.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the shapes of the network\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: dense\n",
      "Weights shape: (1, 2)\n",
      "Weights: [[-0.6905117 -0.5012678]]\n",
      "Bias shape: (2,)\n",
      "Biases: [-0.00219724  0.00199965]\n",
      "Layer: dense_1\n",
      "Weights shape: (2, 2)\n",
      "Weights: [[-0.76168513 -0.07221065]\n",
      " [-0.19386083 -0.5950589 ]]\n",
      "Bias shape: (2,)\n",
      "Biases: [-0.00598801 -0.00616396]\n",
      "Layer: dense_2\n",
      "Weights shape: (2, 1)\n",
      "Weights: [[0.9337305 ]\n",
      " [0.67886657]]\n",
      "Bias shape: (1,)\n",
      "Biases: [-0.00800926]\n"
     ]
    }
   ],
   "source": [
    "for layer in model_1.layers:\n",
    "\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"Weights shape: {weights.shape}\")\n",
    "    print(f\"Weights: {weights}\")\n",
    "    print(f\"Bias shape: {biases.shape}\")\n",
    "    print(f\"Biases: {biases}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters shown in our summary corresond to the weights and biases from our model.\n",
    "\n",
    "* In the first dense layer, we have 2 weights + 2 biases.\n",
    "\n",
    "* In the second layer, we have 2 weights from the previous layer multiplied by the 2 weights from that second layer, plus 2 biases from the second layer, making it 6 parameters.\n",
    "\n",
    "* In the third layer, it is 2 weights from the previous layer multiplied by only 1 weight from that output layer, plus one bias from that output layer, making it 3 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer parameters are parameters created for the optimizer. In this case, we are using the [SGD optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD). These two parameters correspond to `learning rate` and the other one for a `step counter` maintained by the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight values with Forward and Back Propagation\n",
    "\n",
    "As we explained in \"the basics\" notebook, each layer is formed by neurons. Each of these neurons are going to have weights, set as random values. We set the random seed at the beginning to ensure that these weights are still randomized but makes it easier for us to reproduce our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed weights:\n",
      "tf.Tensor(\n",
      "[[ 0.39377618 -0.19760752  0.17610478]\n",
      " [-0.6580951   0.9120474   0.59346676]\n",
      " [ 0.6893079   0.9425578   0.31834674]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.39377618 -0.19760752  0.17610478]\n",
      " [-0.6580951   0.9120474   0.59346676]\n",
      " [ 0.6893079   0.9425578   0.31834674]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(10)  # Set seed for reproducibility\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "weights_1 = initializer(shape=(3, 3))\n",
    "\n",
    "tf.random.set_seed(10)  # Reset seed\n",
    "weights_2 = initializer(shape=(3, 3))\n",
    "\n",
    "print(\"Random seed weights:\")\n",
    "print(weights_1)\n",
    "print(weights_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These neurons output consist on the formula:\n",
    "\n",
    "$z=W⋅x+b$\n",
    "Where :\n",
    "\n",
    "* $W$: Weight vector for the neuron.\n",
    "* $x$: Input vector from the previous layer ( $x=a^{prev}  f(z)$).\n",
    "* $b$: Bias for the neuron.\n",
    "* $z$: Weighted sum before applying activation.\n",
    "\n",
    "Our Z is passed through our activation function. If we don't specify anything when creating a layer, like in the some basic models we have built in our TF-regression notebook, we would have a passthrough function ( or also known as [linear function](https://www.tensorflow.org/api_docs/python/tf/keras/activations/linear)). In our multiclassification network, We have set [RelU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU).\n",
    "\n",
    "$a=f(z)$\n",
    "\n",
    "So, when we calculate the first predictions ( these probability matrix that will end up forming the probability array in the output layer), our NN is only computing this function of $z$ and passing values. And this is called the `Forward Pass` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a prediction, the loss is calculated depending the function we are using ( mse or mae are some possible uses). Once we have the loss value, we continue doing the `Backwards pass` or Backproagation. \n",
    "\n",
    "In this step, the weights and the biases are adjusted after calculating the gradiant descends following the formula:\n",
    "\n",
    "\n",
    "$W ← w - η \\small\\frac{\\partial L}{\\partial W} $\n",
    "\n",
    "​Where:\n",
    "* W is the updated weight.\n",
    "* w is the previous weight.\n",
    "* η is the learning rate.\n",
    " \n",
    "* $ \\small\\frac{\\partial L}{\\partial W}$\n",
    "is the loss gradient with respect to the weight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for our biases would be \n",
    "\n",
    "$B ← b - η \\small\\frac{\\partial L}{\\partial b} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a glimpse of how our array of weights and biases look in the model we created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All biases :  [array([-0.00219724,  0.00199965], dtype=float32), array([-0.00598801, -0.00616396], dtype=float32), array([-0.00800926], dtype=float32)]\n",
      "All weights :  [array([[-0.6905117, -0.5012678]], dtype=float32), array([[-0.76168513, -0.07221065],\n",
      "       [-0.19386083, -0.5950589 ]], dtype=float32), array([[0.9337305 ],\n",
      "       [0.67886657]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Create some list to store the arrays of weights and biases from each layer\n",
    "weights_list=[]\n",
    "biases_list=[]\n",
    "for layer in model_1.layers:\n",
    "    weights, biases = layer.get_weights()  # get_weights() returns [weights, biases]\n",
    "    weights_list.append(weights)\n",
    "    biases_list.append(biases)\n",
    "print(\"All biases : \",biases_list)\n",
    "print(\"All weights : \",weights_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imitating forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try reproducing this ourselves to see what goes on in this stage of the training. We will take just a piece of the data an emulate how would this data go when doing  the `forward pass` stage.\n",
    "\n",
    "For making it a bit more clear what happens with the activation function in other models as in multiclassification model, we will use [RelU](https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu) as the our activation for our layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a function to simulate the weight creation depending on the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.29604465, -0.21134205]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LayerCreation(input_size=1,neurons=2):\n",
    "    '''\n",
    "    \n",
    "    Creates weight and biases values as we would have in a dense layer\n",
    "    in tensorflow.\n",
    "\n",
    "    Args:\n",
    "    input_size : size of the expected input.\n",
    "    neurons : amount of neurons in the layer.\n",
    "\n",
    "    return:\n",
    "    W_tensor : tensor with weights that compose the layer.\n",
    "    b_tensor : tensor with the biases that compose the layer.\n",
    "    '''\n",
    "    initializer = tf.keras.initializers.Zeros()\n",
    "    random_tensor_w1 = tf.random.Generator.from_seed(10) \n",
    "    W_tensor =  random_tensor_w1.normal(shape=(input_size,neurons))\n",
    "    random_tensor_b1 = tf.random.Generator.from_seed(11) \n",
    "    b_tensor =  initializer(shape=(neurons,))\n",
    "    return W_tensor,b_tensor\n",
    "\n",
    "LayerCreation(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflow library already helps us with converting the inputs to tensors and to the dtypes we already need, but to show here step by step the evolution of the weights, we will also create a function to treat the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareInput(input):\n",
    "    '''\n",
    "    This function prepares the input array so it is ready to be introduced\n",
    "    to the input layer we are creating as a simulation of a neural network.\n",
    "    \n",
    "    Args:\n",
    "    input : input array we will feed to our first layer.\n",
    "\n",
    "    return:\n",
    "    prepared_input: tensor that is prepared to be introduced in the first layer.\n",
    "    '''\n",
    "    expanded_input = (tf.expand_dims(input, axis=-1))\n",
    "    prepared_input = tf.cast(expanded_input, dtype=tf.float32)\n",
    "    return prepared_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create what would be the 3 layer model for forward propagation but without recurring to the tensorflow models, to see closely how the weights and biases interact in the model with the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[32.]\n",
      " [34.]\n",
      " [36.]\n",
      " [38.]\n",
      " [40.]\n",
      " [42.]\n",
      " [44.]\n",
      " [46.]\n",
      " [48.]], shape=(9, 1), dtype=float32)\n",
      "W1tf : tf.Tensor([[-0.29604465 -0.21134205]], shape=(1, 2), dtype=float32)\n",
      "b1tf : tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n",
      "W2tf : tf.Tensor(\n",
      "[[-0.29604465 -0.21134205]\n",
      " [ 0.01063002  1.5165398 ]], shape=(2, 2), dtype=float32)\n",
      "b2tf : tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n",
      "W3tf : tf.Tensor(\n",
      "[[-0.29604465]\n",
      " [-0.21134205]], shape=(2, 1), dtype=float32)\n",
      "b3tf : tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "input_example = x_train[50:]\n",
    "prepared_input = PrepareInput(input_example)\n",
    "print(prepared_input)\n",
    "\n",
    "# Layer 1\n",
    "\n",
    "W1tf,b1tf = LayerCreation(1,2)\n",
    "\n",
    "print(\"W1tf :\",W1tf)\n",
    "print(\"b1tf :\",b1tf)\n",
    "\n",
    "# Layer 2\n",
    "\n",
    "W2tf,b2tf = LayerCreation(2,2)\n",
    "print(\"W2tf :\",W2tf)\n",
    "print(\"b2tf :\",b2tf)\n",
    "\n",
    "# Layer 3\n",
    "\n",
    "W3tf,b3tf = LayerCreation(2,1)\n",
    "print(\"W3tf :\",W3tf)\n",
    "print(\"b3tf :\",b3tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have prepared the input data, and we have our layers defined with their own weights and biases, let's try to do the forward propagation for the first epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[34.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tf.expand_dims(prepared_input[1], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from the first layer tf.Tensor(\n",
      "[[ -9.473429   -6.7629457]\n",
      " [-10.065518   -7.18563  ]\n",
      " [-10.657607   -7.608314 ]\n",
      " [-11.249697   -8.030998 ]\n",
      " [-11.841785   -8.453682 ]\n",
      " [-12.433875   -8.876367 ]\n",
      " [-13.025965   -9.29905  ]\n",
      " [-13.618053   -9.721734 ]\n",
      " [-14.210143  -10.144419 ]], shape=(9, 2), dtype=float32)\n",
      "weight from the first layer (1, 2)\n",
      "Output from the first layer (9, 2)\n",
      "weight from the second layer (2, 2)\n",
      "Output from the second layer (9, 2)\n",
      "weight from the third layer (2, 1)\n",
      "Prediction from the third layer (9, 1)\n",
      "Prediction from the third layer tf.Tensor(\n",
      "[[0.9354558 ]\n",
      " [0.99392194]\n",
      " [1.052388  ]\n",
      " [1.1108539 ]\n",
      " [1.1693196 ]\n",
      " [1.227786  ]\n",
      " [1.2862515 ]\n",
      " [1.3447179 ]\n",
      " [1.4031837 ]], shape=(9, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Forward propagation stage\n",
    "\n",
    "def linear_activation(x):\n",
    "    '''Linear activation that returns the same value.\n",
    "    '''\n",
    "    return (x)\n",
    "\n",
    "def relu_activation(x):\n",
    "    '''Relu activation that returns the element-wise maximum for 0 and the input value.\n",
    "    '''\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    '''Relu derivative that returns 1 if the input is greater than 0 or returns 0 otherwise.\n",
    "    '''\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def linear_derivative(x):\n",
    "    '''Linear derivative returns one, as the derivative of x is equal to 1 always.\"\n",
    "    '''\n",
    "    return np.ones_like(x)\n",
    "\n",
    "def forward_propagation(input_value,W,b,activation_function=linear_activation):\n",
    "    ''' Calculates the activation values and predictions forwared through the neural network.\n",
    "        Args:\n",
    "        input_value : Initial input or output value from the previous layer.\n",
    "        w : weight values of the layer's neurons.\n",
    "        b : bias values of the layer's neurons.\n",
    "        Return:\n",
    "        Output value from the layer.\n",
    "    '''\n",
    "    Z = (input_value @ W) + b \n",
    "    A = activation_function(Z)\n",
    "    return A\n",
    "\n",
    "\n",
    "A_layer1 = forward_propagation((prepared_input), W1tf,b1tf)\n",
    "print(\"Output from the first layer\",A_layer1)\n",
    "print(\"weight from the first layer\",W1tf.shape)\n",
    "print(\"Output from the first layer\",A_layer1.shape)\n",
    "\n",
    "A_layer2 = forward_propagation(A_layer1,W2tf,b2tf)\n",
    "print(\"weight from the second layer\",W2tf.shape)\n",
    "print(\"Output from the second layer\",A_layer2.shape)\n",
    "\n",
    "Prediction = forward_propagation(A_layer2,W3tf,b3tf)\n",
    "print(\"weight from the third layer\",W3tf.shape)\n",
    "print(\"Prediction from the third layer\",Prediction.shape)\n",
    "print(\"Prediction from the third layer\",Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first epoch here would mean that for the array of X values we passed, all the Y values corresponding to those X values would be 0.19. Of course, this is the first pass and it is very far from what we expect, and that is why now we have to proceed with the backwards propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mae_error(prediction,true_value):\n",
    "      ''' \n",
    "      This function calculates the mean average error from the predictions we made \n",
    "      and the expected value.\n",
    "      Args:\n",
    "      prediction: prediction value obtained in the forward pass.\n",
    "      true_value: actual value from the input we used.\n",
    "      Return:\n",
    "      mean_errors: mean average error.\n",
    "      '''\n",
    "      m = true_value.shape[0]\n",
    "      loss = tf.abs(true_value - prediction)\n",
    "      mean_loss = tf.reduce_sum(loss) / m\n",
    "\n",
    "      return mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 1), dtype=float32, numpy=\n",
       "array([[67.],\n",
       "       [71.],\n",
       "       [75.],\n",
       "       [79.],\n",
       "       [83.],\n",
       "       [87.],\n",
       "       [91.],\n",
       "       [95.],\n",
       "       [99.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_example = y_train[50:]\n",
    "true_value = PrepareInput(output_example)\n",
    "true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(9, 1), dtype=float32, numpy=\n",
       " array([[0.9354558 ],\n",
       "        [0.99392194],\n",
       "        [1.052388  ],\n",
       "        [1.1108539 ],\n",
       "        [1.1693196 ],\n",
       "        [1.227786  ],\n",
       "        [1.2862515 ],\n",
       "        [1.3447179 ],\n",
       "        [1.4031837 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(9, 1), dtype=float32, numpy=\n",
       " array([[67.],\n",
       "        [71.],\n",
       "        [75.],\n",
       "        [79.],\n",
       "        [83.],\n",
       "        [87.],\n",
       "        [91.],\n",
       "        [95.],\n",
       "        [99.]], dtype=float32)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prediction,true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=81.83067>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = calculate_mae_error(Prediction,true_value)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imitating backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have calculated the error, we can proceed with the `Backwards pass`. Bringing back the mathematical formula, this is how we update the weights for our dense layers\n",
    "\n",
    "\n",
    "$W ← w - η \\small\\frac{\\partial L}{\\partial W}$\n",
    "\n",
    "​Where:\n",
    "* W is the updated weight.\n",
    "* w is the previous weight.\n",
    "* η is the learning rate.\n",
    "* $ \\small\\frac{\\partial L}{\\partial W}$ is the loss gradient with respect to the weight.\n",
    "\n",
    "We need to clarify now what is exactly the loss gradient. The loss gradient is obtained by multiplying the computed loss by the activation output from the previous layer transposed.\n",
    "\n",
    "$ \\small\\frac{\\partial L}{\\partial W_n} = dZ_n ⋅ A^T_{n-1} $\n",
    "​\n",
    "\n",
    "In the third layer, the computed gradient is the mean averague value error between the true value and the prediction. \n",
    "\n",
    "$ dZ_3=f'( y_{pred} -y_{true} ) $\n",
    "\n",
    "\n",
    "And how do we calculate the local gradient from the current layer ? we do it following this expression:\n",
    "\n",
    "$  dZ_n =(dZ_{n+1}⋅W^T_{n+1})⋅f′(Z_n) $\n",
    "\n",
    "​Where:\n",
    "* $dZ_{n+1}$ is the gradient loss with the respect the output of the posterior layer.\n",
    "\n",
    "* $W^T_{n+1}$ is the transposed weight matrix from the third layer.\n",
    "\n",
    "* $f′(Z_n)$ is the derivative of the activation function from the output obtained from the current layer.\n",
    "\n",
    "It is a bit cumbersome but I hope it makes sense, and now with the code written below it might be easier to see.\n",
    "\n",
    "We specify the learning rate, and we choose a default η= 0.01. We only need to calculate the gradient loss for each layer and apply the derivative function to the output obtained from each layer in order to update our weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObtainLocalGradient(dZ_post,Z,post_layer_weight,derivative_function=linear_derivative):\n",
    "    '''Function to calculate the local gradient for the first and second layer.\n",
    "\n",
    "    Args:\n",
    "    dZ_post : loss gradient from the layer that goes after the current layer.\n",
    "    Z : result from the activation function we had in the forward propagation\n",
    "        from this layer before.\n",
    "    post_layer_weight: weights from the posterior layer.\n",
    "\n",
    "    return:\n",
    "    dZ : gradient of the loss function with respect to the current laayer.\n",
    "    '''\n",
    "\n",
    "    dA = tf.matmul(dZ_post,post_layer_weight,transpose_b=True)\n",
    "    #print(\"dA is \",dA)\n",
    "    f_Z = derivative_function(Z)\n",
    "    dZ = dA * f_Z\n",
    "    #print(\"dz is \",dZ)\n",
    "    return dZ\n",
    "\n",
    "def UpdatedWeightValue(dZ,Aminus,weight,n=0.0001):\n",
    "    '''Function used to calculate the updated value of the weights.\n",
    "\n",
    "    Args:\n",
    "    dZ: loss gradient\n",
    "    n: learning rate\n",
    "    x: weight \n",
    "\n",
    "    return:\n",
    "    update: updated weights.\n",
    "    '''\n",
    "\n",
    "    #print(\"A minus shape \",Aminus.shape)\n",
    "    #print(\"Dz shape \",dZ.shape)\n",
    "    #print(\"Casted minus \",tf.cast(tf.shape(Aminus)[0], tf.float32) )\n",
    "    \n",
    "    dW= tf.matmul(Aminus,dZ,transpose_a=True)/ tf.cast(tf.shape(Aminus)[0], tf.float32) \n",
    "    #print(\"DW is \",dW)\n",
    "    weight -= n* dW\n",
    "\n",
    "    return weight\n",
    "\n",
    "def UpdatedBiasValue(dZ,bias,n=0.0001):\n",
    "    '''Function used to calculate the updated value of the biases.\n",
    "    \n",
    "    Args:\n",
    "    dZ: loss gradient\n",
    "    n: learning rate\n",
    "    x: weight or bias\n",
    "\n",
    "    return:\n",
    "    update: updated biases.\n",
    "    '''\n",
    "\n",
    "    db = tf.reduce_sum(dZ, axis=0, keepdims=True)\n",
    "    bias -= n* db\n",
    "    return bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For  $dZ_{3}$, we have that the local gradient is  $f′(Z_3)$.\n",
    "$(Z_3 = mae)$, and because the derivative of the linear function returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 1), dtype=float32, numpy=\n",
       "array([[-66.064545],\n",
       "       [-70.00608 ],\n",
       "       [-73.94761 ],\n",
       "       [-77.889145],\n",
       "       [-81.83068 ],\n",
       "       [-85.77222 ],\n",
       "       [-89.713745],\n",
       "       [-93.65528 ],\n",
       "       [-97.59682 ]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ3= Prediction - true_value\n",
    "dZ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 2), dtype=float32, numpy=\n",
       "array([[  2.7326677,  -8.254143 ],\n",
       "       [  2.9034595,  -8.770027 ],\n",
       "       [  3.074251 ,  -9.285911 ],\n",
       "       [  3.2450428,  -9.801795 ],\n",
       "       [  3.4158344, -10.3176775],\n",
       "       [  3.5866263, -10.833563 ],\n",
       "       [  3.7574182, -11.349445 ],\n",
       "       [  3.9282095, -11.86533  ],\n",
       "       [  4.0990014, -12.381214 ]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A minus shape  (9, 2)\n",
      "Dz shape  (9, 1)\n",
      "Casted minus  tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "DW is  tf.Tensor(\n",
      "[[-284.00793]\n",
      " [ 857.8584 ]], shape=(2, 1), dtype=float32)\n",
      "new weights for layer 3:  tf.Tensor(\n",
      "[[-0.26764387]\n",
      " [-0.2971279 ]], shape=(2, 1), dtype=float32)\n",
      "new bias for layer 3:  tf.Tensor([[0.0736476]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Layer 3\n",
    "\n",
    "new_wtf3 = UpdatedWeightValue(dZ3,A_layer2,W3tf)\n",
    "new_btf3 = UpdatedBiasValue(dZ3,b3tf)\n",
    "print(\"new weights for layer 3: \",new_wtf3)\n",
    "print(\"new bias for layer 3: \",new_btf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do the same for the other two layers. First, we obtain the local gradient for the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA is  tf.Tensor(\n",
      "[[19.558054 13.962216]\n",
      " [20.724926 14.795229]\n",
      " [21.891794 15.62824 ]\n",
      " [23.058664 16.461252]\n",
      " [24.225534 17.294264]\n",
      " [25.392406 18.127275]\n",
      " [26.559275 18.960287]\n",
      " [27.726145 19.793299]\n",
      " [28.893015 20.626312]], shape=(9, 2), dtype=float32)\n",
      "dz is  tf.Tensor(\n",
      "[[19.558054 13.962216]\n",
      " [20.724926 14.795229]\n",
      " [21.891794 15.62824 ]\n",
      " [23.058664 16.461252]\n",
      " [24.225534 17.294264]\n",
      " [25.392406 18.127275]\n",
      " [26.559275 18.960287]\n",
      " [27.726145 19.793299]\n",
      " [28.893015 20.626312]], shape=(9, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 2), dtype=float32, numpy=\n",
       "array([[19.558054, 13.962216],\n",
       "       [20.724926, 14.795229],\n",
       "       [21.891794, 15.62824 ],\n",
       "       [23.058664, 16.461252],\n",
       "       [24.225534, 17.294264],\n",
       "       [25.392406, 18.127275],\n",
       "       [26.559275, 18.960287],\n",
       "       [27.726145, 19.793299],\n",
       "       [28.893015, 20.626312]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local gradient for the second layer\n",
    "\n",
    "dZ2 = ObtainLocalGradient(dZ3,A_layer2,W3tf)\n",
    "dZ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A minus shape  (9, 2)\n",
      "Dz shape  (9, 2)\n",
      "Casted minus  tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "DW is  tf.Tensor(\n",
      "[[-291.47955 -208.08308]\n",
      " [-208.08308 -148.54755]], shape=(2, 2), dtype=float32)\n",
      "new weights for layer 2:  tf.Tensor(\n",
      "[[-0.2668967  -0.19053374]\n",
      " [ 0.03143832  1.5313946 ]], shape=(2, 2), dtype=float32)\n",
      "new bias for layer 2:  tf.Tensor([[-0.02180298 -0.01556484]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Layer 2\n",
    "\n",
    "new_wtf2 = UpdatedWeightValue(dZ2,A_layer1,W2tf)\n",
    "new_btf2 = UpdatedBiasValue(dZ2,b2tf)\n",
    "\n",
    "print(\"new weights for layer 2: \",new_wtf2)\n",
    "print(\"new bias for layer 2: \",new_btf2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And doing it for the first layer finally would update the weights for the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA is  tf.Tensor(\n",
      "[[ -8.740861  21.38216 ]\n",
      " [ -9.262358  22.65786 ]\n",
      " [ -9.783853  23.933558]\n",
      " [-10.305349  25.209257]\n",
      " [-10.826845  26.484959]\n",
      " [-11.348341  27.760656]\n",
      " [-11.869837  29.036356]\n",
      " [-12.391333  30.312056]\n",
      " [-12.912829  31.587757]], shape=(9, 2), dtype=float32)\n",
      "dz is  tf.Tensor(\n",
      "[[ -8.740861  21.38216 ]\n",
      " [ -9.262358  22.65786 ]\n",
      " [ -9.783853  23.933558]\n",
      " [-10.305349  25.209257]\n",
      " [-10.826845  26.484959]\n",
      " [-11.348341  27.760656]\n",
      " [-11.869837  29.036356]\n",
      " [-12.391333  30.312056]\n",
      " [-12.912829  31.587757]], shape=(9, 2), dtype=float32)\n",
      "A minus shape  (9, 1)\n",
      "Dz shape  (9, 2)\n",
      "Casted minus  tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "DW is  tf.Tensor([[-440.02707 1076.4076 ]], shape=(1, 2), dtype=float32)\n",
      "new weights for layer 1:  tf.Tensor([[-0.25204194 -0.3189828 ]], shape=(1, 2), dtype=float32)\n",
      "new bias for layer 1:  tf.Tensor([[ 0.00974416 -0.02383646]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Local gradient for the first layer\n",
    "\n",
    "dZ1 = ObtainLocalGradient(dZ2,A_layer1,W2tf)\n",
    "\n",
    "#Layer 1\n",
    "\n",
    "new_wtf1 = UpdatedWeightValue(dZ1,prepared_input,W1tf)\n",
    "new_btf1 = UpdatedBiasValue(dZ1,b1tf)\n",
    "\n",
    "print(\"new weights for layer 1: \",new_wtf1)\n",
    "print(\"new bias for layer 1: \",new_btf1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would have updated all weights and complete a first epoch. This is what we are doing internally with the tensorflow library when we train a neural network : we pass through the data with the weights we have and using the activation function we have prefered to use for our experiment. Then, we obtain a prediction that we use to compare to the actual results we know beforehand with the real values. After obtaining this value, we calculate de error gradient and local gradient and pass it backwards, updating the values of the weights to maintain the weights that have helped to achieve the desired results and tune the ones that get our value off from the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all together, running epochs\n",
    "\n",
    "Let's try now to build up a function to run forward propagation and back propagation progressively, and see if we can manage to obtain similar results to the ones obtained when creating a model in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = []\n",
    "list.append(1)\n",
    "list.append(11)\n",
    "list_2 = [1,1]\n",
    "\n",
    "np.average(np.subtract(list,list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the neural network with given input, hidden, and output sizes.\n",
    "        \"\"\"\n",
    "\n",
    "        # Call the function to initialize weights and biases\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes the weights and biases for the 3 layers\n",
    "        \"\"\"\n",
    "        # Layer 1\n",
    "\n",
    "        self.W1,self.b1 = LayerCreation(1,2)\n",
    "\n",
    "        # Layer 2\n",
    "\n",
    "        self.W2,self.b2 = LayerCreation(2,2)\n",
    "\n",
    "        # Layer 3\n",
    "\n",
    "        self.W3,self.b3 = LayerCreation(2,1)\n",
    "\n",
    "        self.initialize_predictions()\n",
    "\n",
    "    def self_forward_propagation(self, input):\n",
    "        \"\"\"\n",
    "        Performs forward propagation to get the predictions.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        A_layer1 = forward_propagation(input, self.W1,self.b1)\n",
    "        self.A_layer1 = A_layer1\n",
    "\n",
    "        A_layer2 = forward_propagation(A_layer1,self.W2,self.b2)\n",
    "        self.A_layer2 = A_layer2\n",
    "\n",
    "        self.y_pred = forward_propagation(A_layer2,self.W3,self.b3)\n",
    "        \n",
    "        #self.y_prediction.append(y_pred)\n",
    "\n",
    "\n",
    "\n",
    "    def self_backward_propagation(self,input, y_true,):\n",
    "        \"\"\"\n",
    "        Performs backward propagation to update the weights and biases and calculates\n",
    "        the mae.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        mae = calculate_mae_error(self.y_pred,y_true)\n",
    "        dZ3= self.y_pred - y_true\n",
    "\n",
    "        print(\"Loss is : \",mae)\n",
    "\n",
    "        print(\"Backward prop ongoing \")\n",
    "        print(\"dz3 shape is \",dZ3.shape)\n",
    "        print(\"A_layer2 shape is \",self.A_layer2.shape)\n",
    "        print(\"W3 shape is \",self.W3.shape)\n",
    "        \n",
    "        new_w3 = UpdatedWeightValue(dZ3,self.A_layer2,self.W3)\n",
    "        new_b3 = UpdatedBiasValue(dZ3,self.b3)\n",
    "\n",
    "        dZ2 = ObtainLocalGradient(dZ3,self.A_layer2,self.W3)\n",
    "\n",
    "        new_w2 = UpdatedWeightValue(dZ2,self.A_layer1,self.W2)\n",
    "        new_b2 = UpdatedBiasValue(dZ2,self.b3)\n",
    "\n",
    "        dZ1 = ObtainLocalGradient(dZ2,self.A_layer1,self.W2)\n",
    "\n",
    "        new_w1 = UpdatedWeightValue(dZ1,input,self.W1)\n",
    "        new_b1 = UpdatedBiasValue(dZ1,self.b1)\n",
    "\n",
    "        self.update_self_weights(new_w3,new_b3,new_w2,new_b2,new_w1,new_b1)\n",
    "        self.initialize_predictions()\n",
    "        \n",
    "        return mae\n",
    "    \n",
    "    def update_self_weights(self,new_w3,new_b3,new_w2,new_b2,new_w1,new_b1):\n",
    "        \"\"\"\n",
    "        Stores the new values of weights and biases.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.W3 = new_w3\n",
    "        self.b3 = new_b3\n",
    "        self.W2 = new_w2\n",
    "        self.b2 = new_b2\n",
    "        self.W1 = new_w1\n",
    "        self.b1 = new_b1\n",
    "    \n",
    "    def train_network(self,input,y_true,number_epoch):\n",
    "        \"\"\"\n",
    "        Runs a certain amount of epochs to train the network.\n",
    "        \n",
    "        \"\"\"\n",
    "        for epoch in range(number_epoch):\n",
    "            #for iteration in range(prepared_input.shape[0]):\n",
    "            #    print(\"Iteration \",iteration)\n",
    "            #    self.self_forward_propagation(PrepareInput(input[iteration]))\n",
    "            #    mae = self.self_backward_propagation(PrepareInput(input[iteration]),PrepareInput(y_true[iteration]))\n",
    "            #    print(\"mae is \",mae)\n",
    "            #    print(\"average is  is \",np.mean(mae))\n",
    "            #    self.show_weights()\n",
    "            #    self.show_biases()\n",
    "            self.self_forward_propagation(input)\n",
    "            mae = self.self_backward_propagation(input,y_true)\n",
    "            print(\"mae is \",mae)\n",
    "            #print(\"average is  is \",np.mean(mae))\n",
    "            self.show_weights()\n",
    "            self.show_biases()\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                # Print the loss every 10 iterations\n",
    "                print(f\"Epoch {epoch+1}/{number_epoch}, Loss: {np.mean(mae)}\")\n",
    "                \n",
    "\n",
    "    def show_weights(self):\n",
    "        \"\"\"\n",
    "        Prints weight values\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"Weights from first layer : \",self.W1)\n",
    "        print(\"Weights from second layer : \",self.W2)\n",
    "        print(\"Weights from third layer : \",self.W3)\n",
    "\n",
    "    def show_biases(self):\n",
    "        \"\"\"\n",
    "        Prints bias values\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"Biases from first layer : \",self.b1)\n",
    "        print(\"Biases from second layer : \",self.b2)\n",
    "        print(\"Biases from third layer : \",self.b3)    \n",
    "\n",
    "    def get_prediction(self):\n",
    "        \"\"\"\n",
    "        returns prediction\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.y_pred\n",
    "    \n",
    "    def initialize_predictions(self):\n",
    "        \"\"\"\n",
    "        Initializes prediction class variable. Must do when creating the NN and after each epoch.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.y_prediction=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network2 = OurNeuralNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights from first layer :  tf.Tensor([[-0.29604465 -0.21134205]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.29604465 -0.21134205]\n",
      " [ 0.01063002  1.5165398 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.29604465]\n",
      " [-0.21134205]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "our_network2.show_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network2.self_forward_propagation(prepared_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 1), dtype=float32, numpy=\n",
       "array([[32.],\n",
       "       [34.],\n",
       "       [36.],\n",
       "       [38.],\n",
       "       [40.],\n",
       "       [42.],\n",
       "       [44.],\n",
       "       [46.],\n",
       "       [48.]], dtype=float32)>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 1), dtype=float32, numpy=\n",
       "array([[67.],\n",
       "       [71.],\n",
       "       [75.],\n",
       "       [79.],\n",
       "       [83.],\n",
       "       [87.],\n",
       "       [91.],\n",
       "       [95.],\n",
       "       [99.]], dtype=float32)>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = our_network2.get_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 1), dtype=float32, numpy=\n",
       "array([[ 66.943016],\n",
       "       [ 71.10693 ],\n",
       "       [ 75.27084 ],\n",
       "       [ 79.43475 ],\n",
       "       [ 83.59868 ],\n",
       "       [ 87.76258 ],\n",
       "       [ 91.926506],\n",
       "       [ 96.090416],\n",
       "       [100.25432 ]], dtype=float32)>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.83067"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.subtract(true_value,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is :  tf.Tensor(81.83067, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (9, 1)\n",
      "A_layer2 shape is  (9, 2)\n",
      "W3 shape is  (2, 1)\n",
      "A minus shape  (9, 2)\n",
      "Dz shape  (9, 1)\n",
      "Casted minus  tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "DW is  tf.Tensor(\n",
      "[[-284.00793]\n",
      " [ 857.8584 ]], shape=(2, 1), dtype=float32)\n",
      "dA is  tf.Tensor(\n",
      "[[19.558054 13.962216]\n",
      " [20.724926 14.795229]\n",
      " [21.891794 15.62824 ]\n",
      " [23.058664 16.461252]\n",
      " [24.225534 17.294264]\n",
      " [25.392406 18.127275]\n",
      " [26.559275 18.960287]\n",
      " [27.726145 19.793299]\n",
      " [28.893015 20.626312]], shape=(9, 2), dtype=float32)\n",
      "dz is  tf.Tensor(\n",
      "[[19.558054 13.962216]\n",
      " [20.724926 14.795229]\n",
      " [21.891794 15.62824 ]\n",
      " [23.058664 16.461252]\n",
      " [24.225534 17.294264]\n",
      " [25.392406 18.127275]\n",
      " [26.559275 18.960287]\n",
      " [27.726145 19.793299]\n",
      " [28.893015 20.626312]], shape=(9, 2), dtype=float32)\n",
      "A minus shape  (9, 2)\n",
      "Dz shape  (9, 2)\n",
      "Casted minus  tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "DW is  tf.Tensor(\n",
      "[[-291.47955 -208.08308]\n",
      " [-208.08308 -148.54755]], shape=(2, 2), dtype=float32)\n",
      "dA is  tf.Tensor(\n",
      "[[ -8.740861  21.38216 ]\n",
      " [ -9.262358  22.65786 ]\n",
      " [ -9.783853  23.933558]\n",
      " [-10.305349  25.209257]\n",
      " [-10.826845  26.484959]\n",
      " [-11.348341  27.760656]\n",
      " [-11.869837  29.036356]\n",
      " [-12.391333  30.312056]\n",
      " [-12.912829  31.587757]], shape=(9, 2), dtype=float32)\n",
      "dz is  tf.Tensor(\n",
      "[[ -8.740861  21.38216 ]\n",
      " [ -9.262358  22.65786 ]\n",
      " [ -9.783853  23.933558]\n",
      " [-10.305349  25.209257]\n",
      " [-10.826845  26.484959]\n",
      " [-11.348341  27.760656]\n",
      " [-11.869837  29.036356]\n",
      " [-12.391333  30.312056]\n",
      " [-12.912829  31.587757]], shape=(9, 2), dtype=float32)\n",
      "A minus shape  (9, 1)\n",
      "Dz shape  (9, 2)\n",
      "Casted minus  tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "DW is  tf.Tensor([[-440.02707 1076.4076 ]], shape=(1, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=81.83067>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_network2.self_backward_propagation(prepared_input,true_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is :  tf.Tensor(78.28142, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (9, 1)\n",
      "A_layer2 shape is  (9, 2)\n",
      "W3 shape is  (2, 1)\n",
      "A minus shape  (9, 2)\n",
      "Dz shape  (9, 1)\n",
      "Casted minus  tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "DW is  tf.Tensor(\n",
      "[[-180.14333]\n",
      " [1405.5679 ]], shape=(2, 1), dtype=float32)\n",
      "dA is  tf.Tensor(\n",
      "[[16.916658 18.780222]\n",
      " [17.925379 19.900064]\n",
      " [18.9341   21.019907]\n",
      " [19.942822 22.139751]\n",
      " [20.951542 23.259594]\n",
      " [21.960262 24.379436]\n",
      " [22.968983 25.499279]\n",
      " [23.977703 26.619122]\n",
      " [24.986423 27.738964]], shape=(9, 2), dtype=float32)\n",
      "dz is  tf.Tensor(\n",
      "[[16.916658 18.780222]\n",
      " [17.925379 19.900064]\n",
      " [18.9341   21.019907]\n",
      " [19.942822 22.139751]\n",
      " [20.951542 23.259594]\n",
      " [21.960262 24.379436]\n",
      " [22.968983 25.499279]\n",
      " [23.977703 26.619122]\n",
      " [24.986423 27.738964]], shape=(9, 2), dtype=float32)\n",
      "A minus shape  (9, 2)\n",
      "Dz shape  (9, 2)\n",
      "Casted minus  tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "DW is  tf.Tensor(\n",
      "[[-214.4124  -238.0324 ]\n",
      " [-272.11685 -302.09363]], shape=(2, 2), dtype=float32)\n",
      "dA is  tf.Tensor(\n",
      "[[ -8.0932665  29.291761 ]\n",
      " [ -8.575858   31.038395 ]\n",
      " [ -9.058451   32.78503  ]\n",
      " [ -9.541042   34.531666 ]\n",
      " [-10.023635   36.278297 ]\n",
      " [-10.5062275  38.024933 ]\n",
      " [-10.988818   39.771564 ]\n",
      " [-11.471411   41.518196 ]\n",
      " [-11.954002   43.26483  ]], shape=(9, 2), dtype=float32)\n",
      "dz is  tf.Tensor(\n",
      "[[ -8.0932665  29.291761 ]\n",
      " [ -8.575858   31.038395 ]\n",
      " [ -9.058451   32.78503  ]\n",
      " [ -9.541042   34.531666 ]\n",
      " [-10.023635   36.278297 ]\n",
      " [-10.5062275  38.024933 ]\n",
      " [-10.988818   39.771564 ]\n",
      " [-11.471411   41.518196 ]\n",
      " [-11.954002   43.26483  ]], shape=(9, 2), dtype=float32)\n",
      "A minus shape  (9, 1)\n",
      "Dz shape  (9, 2)\n",
      "Casted minus  tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "DW is  tf.Tensor([[-407.37994 1474.4204 ]], shape=(1, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=78.28142>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_network2.self_forward_propagation(prepared_input)\n",
    "our_network2.self_backward_propagation(prepared_input,true_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights from first layer :  tf.Tensor([[-0.12176175 -1.0760895 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.21693967 -0.10176457]\n",
      " [ 0.15463372  1.8046185 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.25157312]\n",
      " [-1.048601  ]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "our_network2.show_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = np.arange(0,10,1)\n",
    "y_new = OurLinearCorrelation(x_new)\n",
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 34, 36, 38, 40, 42, 44, 46, 48])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67, 71, 75, 79, 83, 87, 91, 95, 99])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]\n",
      " [6.]\n",
      " [7.]\n",
      " [8.]\n",
      " [9.]], shape=(10, 1), dtype=float32) tf.Tensor(\n",
      "[[ 3.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [11.]\n",
      " [13.]\n",
      " [15.]\n",
      " [17.]\n",
      " [19.]\n",
      " [21.]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_prep = PrepareInput(x_new)\n",
    "y_prep = PrepareInput(y_new)\n",
    "print(x_prep,y_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_network3 = OurNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is :  tf.Tensor(11.204785, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=11.204785>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_network3.self_forward_propagation(x_prep)\n",
    "our_network3.self_backward_propagation(x_prep,y_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[0.29319263],\n",
       "       [0.40475315],\n",
       "       [0.5163137 ],\n",
       "       [0.6278742 ],\n",
       "       [0.7394346 ],\n",
       "       [0.8509952 ],\n",
       "       [0.96255565],\n",
       "       [1.0741162 ],\n",
       "       [1.1856767 ],\n",
       "       [1.2972373 ]], dtype=float32)>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3 = our_network3.get_prediction()\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is :  tf.Tensor(11.184079, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(11.184079, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.25944176 -0.32007408]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.27454513 -0.19226532]\n",
      " [ 0.03217968  1.5361695 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.26574814]\n",
      " [-0.30259207]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.06223631 -0.18485752]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.45916638 0.45879436]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.47333246]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(11.163118, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(11.163118, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.25857934 -0.3231873 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.27411017 -0.19177005]\n",
      " [ 0.03279391  1.5368689 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2648606]\n",
      " [-0.3053158]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.06370021 -0.19014196]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.47036588 0.46995458]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.48449558]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(11.141898, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(11.141898, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2577184  -0.32632452]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.27367938 -0.19127347]\n",
      " [ 0.03341193  1.5375813 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.26396722]\n",
      " [-0.30806637]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.06516149 -0.19546686]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.48154452 0.4810938 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.49563748]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(11.120417, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(11.120417, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.25685897 -0.32948592]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.27325276 -0.19077559]\n",
      " [ 0.0340337   1.538307  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2630681 ]\n",
      " [-0.31084403]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.06662013 -0.20083243]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.49270204 0.49221164]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.5067579]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(11.098664, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(11.098664, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.25600106 -0.3326716 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2728303  -0.19027641]\n",
      " [ 0.03465919  1.539046  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2621634 ]\n",
      " [-0.31364897]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.06807611 -0.20623888]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.5038382  0.50330794]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.5178566]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(11.076636, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(11.076636, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.25514466 -0.33588174]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.272412   -0.18977596]\n",
      " [ 0.03528835  1.5397987 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.26125318]\n",
      " [-0.31648138]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.06952944 -0.21168645]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.5149527 0.5143824]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.5289332]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(11.05433, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(11.05433, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.25428978 -0.33911642]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.27199784 -0.18927425]\n",
      " [ 0.03592113  1.5405653 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.26033756]\n",
      " [-0.31934148]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.07098009 -0.21717533]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.52604526 0.52543473]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.53998756]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(11.031736, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(11.031736, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.25343642 -0.3423758 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.27158782 -0.1887713 ]\n",
      " [ 0.03655749  1.5413458 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.25941667]\n",
      " [-0.32222944]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.07242805 -0.22270574]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.5371156 0.5364647]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.5510193]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(11.008852, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(11.008852, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2525846 -0.3456599]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2711819  -0.18826711]\n",
      " [ 0.03719738  1.5421407 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2584906 ]\n",
      " [-0.32514548]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.07387331 -0.22827788]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.5481634  0.54747194]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.56202817]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.98567, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.98567, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.25173435 -0.34896895]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.27078012 -0.18776171]\n",
      " [ 0.03784076  1.54295   ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.25755945]\n",
      " [-0.32808977]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.07531586 -0.23389195]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.5591885  0.55845624]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.57301384]], shape=(1, 1), dtype=float32)\n",
      "Epoch 10/100, Loss: 10.98567008972168\n",
      "Loss is :  tf.Tensor(10.962186, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.962186, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.25088564 -0.35230303]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.27038243 -0.18725511]\n",
      " [ 0.03848758  1.543774  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2566234 ]\n",
      " [-0.33106253]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.07675569 -0.23954813]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.5701904  0.56941724]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.58397603]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.938392, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.938392, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2500385  -0.35566223]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26998883 -0.18674734]\n",
      " [ 0.03913779  1.5446128 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2556825 ]\n",
      " [-0.33406392]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.07819277 -0.24524662]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.581169   0.58035475]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.59491444]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.914283, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.914283, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.24919294 -0.35904667]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26959932 -0.18623841]\n",
      " [ 0.03979133  1.5454667 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.25473693]\n",
      " [-0.33709413]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.07962709 -0.2509876 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.59212387 0.59126836]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.6058287]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.8898535, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.8898535, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.24834897 -0.36245644]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26921386 -0.18572834]\n",
      " [ 0.04044816  1.5463358 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.25378677]\n",
      " [-0.34015334]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.08105864 -0.25677124]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.60305464 0.6021578 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.61671853]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.865095, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.865095, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2475066  -0.36589164]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26883245 -0.18521716]\n",
      " [ 0.04110822  1.5472205 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.25283217]\n",
      " [-0.34324175]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.08248739 -0.2625977 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.6139611  0.61302274]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.6275836]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.840006, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.840006, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.24666585 -0.36935237]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2684551  -0.18470487]\n",
      " [ 0.04177145  1.5481209 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.25187325]\n",
      " [-0.3463595 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.08391333 -0.2684672 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.62484294 0.62386286]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.6384236]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.814575, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.814575, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.24582674 -0.3728387 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26808175 -0.18419151]\n",
      " [ 0.04243781  1.5490372 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.25091013]\n",
      " [-0.34950677]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.08533642 -0.27437982]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.63569975 0.6346779 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.64923817]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.788798, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.788798, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.24498926 -0.37635076]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26771244 -0.18367709]\n",
      " [ 0.04310723  1.5499697 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.24994294]\n",
      " [-0.3526837 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.08675667 -0.28033575]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.64653116 0.6454674 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.66002697]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.762668, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.762668, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.24415344 -0.3798886 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26734716 -0.18316165]\n",
      " [ 0.04377966  1.5509185 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2489718 ]\n",
      " [-0.35589045]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.08817404 -0.2863351 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.6573369  0.65623116]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.67078966]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.736178, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.736178, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.24331929 -0.38345227]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26698586 -0.18264519]\n",
      " [ 0.04445503  1.5518838 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.24799687]\n",
      " [-0.3591272 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.0895885  -0.29237804]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.6681166  0.66696876]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.6815258]], shape=(1, 1), dtype=float32)\n",
      "Epoch 20/100, Loss: 10.736178398132324\n",
      "Loss is :  tf.Tensor(10.709323, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.709323, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.24248683 -0.38704187]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26662853 -0.18212774]\n",
      " [ 0.04513329  1.552866  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.24701826]\n",
      " [-0.36239406]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.09100004 -0.29846466]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.67886996 0.67767984]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.6922352]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.682095, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.682095, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.24165608 -0.39065745]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26627517 -0.18160935]\n",
      " [ 0.04581437  1.5538652 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.24603613]\n",
      " [-0.3656912 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.09240862 -0.30459508]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.6895965 0.688364 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.7029173]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.654486, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.654486, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.24082705 -0.3942991 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26592577 -0.18109003]\n",
      " [ 0.04649822  1.5548816 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2450506 ]\n",
      " [-0.36901876]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.09381422 -0.31076944]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.70029587 0.69902104]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.7135718]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.62649, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.62649, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23999976 -0.39796683]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2655803  -0.1805698 ]\n",
      " [ 0.04718475  1.5559155 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2440618 ]\n",
      " [-0.37237686]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.09521683 -0.31698778]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.7109678 0.7096504]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.7241983]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.5981, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.5981, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23917422 -0.40166074]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26523876 -0.18004869]\n",
      " [ 0.04787393  1.556967  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.24306989]\n",
      " [-0.3757656 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.09661639 -0.32325023]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.7216117 0.7202518]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.7347964]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.569308, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.569308, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23835047 -0.40538085]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26490113 -0.17952675]\n",
      " [ 0.04856566  1.5580363 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.24207501]\n",
      " [-0.37918508]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.09801289 -0.32955685]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.7322273 0.7308248]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.74536574]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.540109, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.540109, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2375285  -0.40912715]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2645674  -0.17900398]\n",
      " [ 0.04925989  1.5591238 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2410773 ]\n",
      " [-0.38263544]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.09940629 -0.3359077 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.74281424 0.74136907]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.75590587]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.510493, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.510493, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23670836 -0.4128997 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26423755 -0.17848043]\n",
      " [ 0.04995655  1.5602294 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.24007691]\n",
      " [-0.3861168 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.10079656 -0.34230283]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.753372   0.75188416]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.7664164]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.480455, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.480455, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23589006 -0.41669855]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26391155 -0.17795613]\n",
      " [ 0.05065555  1.5613537 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.239074  ]\n",
      " [-0.38962922]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.10218366 -0.34874228]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.7639003 0.7623697]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.77689683]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.449986, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.449986, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23507363 -0.42052364]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2635894  -0.17743112]\n",
      " [ 0.05135685  1.5624967 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.23806871]\n",
      " [-0.39317277]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.10356757 -0.35522607]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.7743985  0.77282524]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.78734684]], shape=(1, 1), dtype=float32)\n",
      "Epoch 30/100, Loss: 10.449986457824707\n",
      "Loss is :  tf.Tensor(10.419081, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.419081, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23425908 -0.42437503]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2632711  -0.17690542]\n",
      " [ 0.05206035  1.5636585 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.23706119]\n",
      " [-0.39674756]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.10494824 -0.3617542 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.7848664  0.78325033]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.7977659]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.387728, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.387728, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23344645 -0.4282527 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2629566  -0.17637907]\n",
      " [ 0.05276599  1.5648395 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.23605157]\n",
      " [-0.40035364]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.10632563 -0.36832672]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.7953034 0.7936446]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.8081536]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.355922, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.355922, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23263575 -0.43215662]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2626459  -0.1758521 ]\n",
      " [ 0.05347368  1.5660398 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.23504004]\n",
      " [-0.40399104]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.10769971 -0.37494358]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.8057091 0.8040076]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.8185096]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.323656, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.323656, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.231827  -0.4360868]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26233897 -0.17532456]\n",
      " [ 0.05418336  1.5672596 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.23402674]\n",
      " [-0.40765986]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.10907044 -0.38160476]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.81608313 0.8143389 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.8288332]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.290921, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.290921, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23102026 -0.44004318]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26203582 -0.17479648]\n",
      " [ 0.05489494  1.5684991 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.23301184]\n",
      " [-0.41136009]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.11043776 -0.38831022]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.8264249 0.824638 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.83912414]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.25771, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.25771, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.23021552 -0.44402573]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26173642 -0.1742679 ]\n",
      " [ 0.05560834  1.5697585 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.23199548]\n",
      " [-0.41509178]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.11180164 -0.39505988]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.836734   0.83490455]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.84938186]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.224015, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.224015, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.22941282 -0.4480344 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26144075 -0.17373887]\n",
      " [ 0.05632348  1.5710381 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.23097783]\n",
      " [-0.41885495]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.11316203 -0.40185368]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.84700996 0.84513795]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.8596059]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.189827, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.189827, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2286122  -0.45206913]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26114878 -0.17320941]\n",
      " [ 0.05704028  1.572338  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.22995906]\n",
      " [-0.4226496 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.1145189  -0.40869153]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.8572523  0.85533786]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.86979574]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.15514, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.15514, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.22781368 -0.45612985]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2608605  -0.17267959]\n",
      " [ 0.05775865  1.5736583 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.22893932]\n",
      " [-0.4264757 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.11587217 -0.4155733 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.8674605  0.86550367]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.8799509]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.119944, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.119944, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.22701728 -0.46021646]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2605759  -0.17214942]\n",
      " [ 0.05847852  1.5749993 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.22791879]\n",
      " [-0.4303333 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.11722182 -0.42249888]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.87763405 0.87563497]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.8900708]], shape=(1, 1), dtype=float32)\n",
      "Epoch 40/100, Loss: 10.119943618774414\n",
      "Loss is :  tf.Tensor(10.084233, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.084233, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.22622305 -0.46432889]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26029494 -0.17161897]\n",
      " [ 0.05919978  1.5763612 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.22689763]\n",
      " [-0.43422228]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.11856778 -0.42946813]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.8877724 0.8857312]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.900155]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.047998, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.047998, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.22543103 -0.468467  ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.26001763 -0.17108828]\n",
      " [ 0.05992237  1.577744  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.22587599]\n",
      " [-0.43814266]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.11991    -0.43648085]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.89787513 0.89579195]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.910203]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(10.0112295, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(10.0112295, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.22464123 -0.47263068]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25974393 -0.17055738]\n",
      " [ 0.06064618  1.579148  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.22485407]\n",
      " [-0.44209436]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.12124843 -0.44353688]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.9079417 0.9058166]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.92021424]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.973924, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.973924, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2238537 -0.4768198]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25947383 -0.17002633]\n",
      " [ 0.06137112  1.5805734 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.22383201]\n",
      " [-0.4460773 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.12258301 -0.450636  ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.91797155 0.9158048 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.9301882]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.936069, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.936069, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.22306849 -0.48103425]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2592073  -0.16949518]\n",
      " [ 0.06209711  1.5820203 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.22281  ]\n",
      " [-0.4500914]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.12391368 -0.457778  ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.92796415 0.9257559 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.9401243]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.897657, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.897657, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.22228561 -0.48527384]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25894436 -0.16896398]\n",
      " [ 0.06282405  1.5834887 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.22178821]\n",
      " [-0.45413655]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.12524039 -0.4649626 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.93791896 0.9356694 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.9500219]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.858683, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.858683, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2215051 -0.4895384]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25868493 -0.16843279]\n",
      " [ 0.06355184  1.5849789 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.22076683]\n",
      " [-0.45821267]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.12656306 -0.47218955]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.9478354 0.9455447]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.9598806]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.819136, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.819136, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.22072703 -0.49382776]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25842902 -0.16790165]\n",
      " [ 0.0642804   1.5864911 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.21974601]\n",
      " [-0.4623196 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.12788165 -0.47945854]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.9577128  0.95538133]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.96969974]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.77901, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.77901, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2199514 -0.4981417]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25817662 -0.16737062]\n",
      " [ 0.06500962  1.5880253 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.21872593]\n",
      " [-0.46645722]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.12919608 -0.48676923]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.9675508 0.9651787]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.9794788]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.7382965, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.7382965, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21917827 -0.50248003]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2579277  -0.16683973]\n",
      " [ 0.06573941  1.5895817 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.21770678]\n",
      " [-0.47062534]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.13050628 -0.4941213 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.97734874 0.9749363 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.98921704]], shape=(1, 1), dtype=float32)\n",
      "Epoch 50/100, Loss: 9.738296508789062\n",
      "Loss is :  tf.Tensor(9.696987, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.696987, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21840769 -0.5068425 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2576822  -0.16630907]\n",
      " [ 0.06646966  1.5911603 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.21668872]\n",
      " [-0.47482377]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.13181219 -0.5015144 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.98710597 0.9846534 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[0.998914]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.655075, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.655075, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2176397  -0.51122886]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25744015 -0.16577868]\n",
      " [ 0.06720029  1.5927613 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.21567194]\n",
      " [-0.47905234]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.13311373 -0.508948  ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[0.9968219 0.9943296]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.0085691]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.612554, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.612554, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21687433 -0.5156388 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25720152 -0.16524862]\n",
      " [ 0.06793118  1.5943848 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.21465662]\n",
      " [-0.4833108 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.13441084 -0.51642185]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.006496  1.0039642]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.0181817]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.569411, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.569411, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21611163 -0.52007216]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25696626 -0.16471894]\n",
      " [ 0.06866223  1.5960308 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.21364294]\n",
      " [-0.48759893]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.13570344 -0.52393544]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.0161276 1.0135567]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.0277511]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.525645, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.525645, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21535166 -0.52452856]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25673437 -0.16418971]\n",
      " [ 0.06939334  1.5976994 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.21263108]\n",
      " [-0.49191648]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.13699146 -0.53148824]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.025716  1.0231063]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.0372767]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.481247, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.481247, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21459445 -0.52900773]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25650582 -0.16366099]\n",
      " [ 0.0701244   1.5993907 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.21162121]\n",
      " [-0.49626318]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.13827482 -0.5390798 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.0352608 1.0326128]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.0467579]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.436207, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.436207, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21384007 -0.5335093 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2562806  -0.16313283]\n",
      " [ 0.07085532  1.6011047 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.21061353]\n",
      " [-0.5006387 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.13955343 -0.54670954]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.0447611 1.042075 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.0561942]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.390521, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.390521, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21308854 -0.53803295]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2560587  -0.16260532]\n",
      " [ 0.07158598  1.6028415 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.20960821]\n",
      " [-0.5050428 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.14082722 -0.5543769 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.0542164 1.0514929]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.0655847]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.344181, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.344181, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21233994 -0.5425783 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25584003 -0.1620785 ]\n",
      " [ 0.07231627  1.6046011 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.20860544]\n",
      " [-0.50947505]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.14209612 -0.5620813 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.063626  1.0608654]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.0749289]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.29718, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.29718, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2115943 -0.5471449]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25562465 -0.16155244]\n",
      " [ 0.07304608  1.6063836 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2076054 ]\n",
      " [-0.51393515]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.14336002 -0.569822  ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.0729895 1.0701922]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.084226]], shape=(1, 1), dtype=float32)\n",
      "Epoch 60/100, Loss: 9.29718017578125\n",
      "Loss is :  tf.Tensor(9.249512, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.249512, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21085168 -0.5517324 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2554125  -0.16102722]\n",
      " [ 0.07377531  1.6081887 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.20660828]\n",
      " [-0.5184227 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.14461884 -0.57759845]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.0823058 1.0794724]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.0934756]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.201171, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.201171, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.21011214 -0.5563404 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25520352 -0.1605029 ]\n",
      " [ 0.07450384  1.6100168 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.20561425]\n",
      " [-0.52293736]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.1458725  -0.58540994]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.0915745 1.0887055]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1026767]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.15215, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.15215, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.20937572 -0.5609684 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25499773 -0.15997954]\n",
      " [ 0.07523156  1.6118677 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.2046235]\n",
      " [-0.5274786]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.14712092 -0.5932557 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.1007949 1.0978907]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1118289]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.102444, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.102444, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2086425 -0.565616 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2547951  -0.1594572 ]\n",
      " [ 0.07595836  1.6137412 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.20363621]\n",
      " [-0.53204596]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.148364   -0.60113496]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.1099664 1.1070275]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1209314]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.052048, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.052048, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.20791252 -0.57028264]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2545956  -0.15893598]\n",
      " [ 0.07668413  1.6156374 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.20265257]\n",
      " [-0.5366391 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.14960162 -0.60904694]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.119088  1.1161153]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1299834]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(9.000955, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(9.000955, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.20718583 -0.57496786]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2543992  -0.15841593]\n",
      " [ 0.07740875  1.6175562 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.20167276]\n",
      " [-0.54125744]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.15083373 -0.61699075]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.1281594 1.1251532]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1389843]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.9491625, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.9491625, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.20646252 -0.5796711 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2542059  -0.15789713]\n",
      " [ 0.07813209  1.6194975 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.20069696]\n",
      " [-0.54590046]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.1520602  -0.62496555]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.1371795 1.1341405]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1479335]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.896663, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.896663, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.20574261 -0.5843918 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25401565 -0.15737964]\n",
      " [ 0.07885406  1.6214613 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.19972534]\n",
      " [-0.5505676 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.15328094 -0.63297045]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.146148  1.1430768]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1568302]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.843455, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.843455, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.20502618 -0.5891293 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25382844 -0.15686356]\n",
      " [ 0.07957453  1.6234473 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.1987581 ]\n",
      " [-0.55525833]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.15449587 -0.6410045 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.155064  1.1519613]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1656736]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.789534, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.789534, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2043133 -0.5938832]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25364423 -0.15634894]\n",
      " [ 0.08029339  1.6254555 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.19779539]\n",
      " [-0.559972  ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.15570487 -0.6490667 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.1639266 1.1607932]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1744632]], shape=(1, 1), dtype=float32)\n",
      "Epoch 70/100, Loss: 8.789533615112305\n",
      "Loss is :  tf.Tensor(8.734896, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.734896, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.20360401 -0.5986527 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.253463   -0.15583587]\n",
      " [ 0.08101051  1.6274858 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.19683743]\n",
      " [-0.564708  ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.15690784 -0.657156  ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.1727355 1.1695719]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1831981]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.679538, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.679538, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2028984  -0.60343724]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25328472 -0.15532441]\n",
      " [ 0.08172577  1.6295378 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.19588436]\n",
      " [-0.56946564]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.15810469 -0.66527134]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.1814896 1.1782967]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.1918776]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.623457, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.623457, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.20219651 -0.60823613]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25310937 -0.15481466]\n",
      " [ 0.08243906  1.6316115 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.19493638]\n",
      " [-0.5742443 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.15929529 -0.67341167]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.1901884 1.1869669]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.2005011]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.566652, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.566652, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.2014984 -0.6130487]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25293693 -0.15430668]\n",
      " [ 0.08315027  1.6337066 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.19399366]\n",
      " [-0.57904327]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.16047956 -0.68157583]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.1988311 1.1955817]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.2090677]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.50912, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.50912, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.20080416 -0.6178742 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25276735 -0.15380056]\n",
      " [ 0.08385926  1.6358228 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.19305636]\n",
      " [-0.58386177]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.16165738 -0.6897626 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.207417  1.2041405]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.2175769]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.450861, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.450861, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.20011385 -0.6227119 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25260064 -0.15329638]\n",
      " [ 0.08456592  1.63796   ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.19212466]\n",
      " [-0.5886991 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.16282864 -0.69797075]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.2159454 1.2126427]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.2260277]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.391874, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.391874, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19942753 -0.62756103]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25243676 -0.15279421]\n",
      " [ 0.08527012  1.6401178 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.19119875]\n",
      " [-0.59355444]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.16399324 -0.7061991 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.2244154 1.2210875]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.2344196]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.332159, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.332159, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19874527 -0.63242084]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25227568 -0.15229413]\n",
      " [ 0.08597176  1.642296  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.19027878]\n",
      " [-0.59842694]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.16515106 -0.7144463 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.2328265 1.229474 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.2427517]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.271717, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.271717, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19806713 -0.6372905 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25211737 -0.15179622]\n",
      " [ 0.0866707   1.6444942 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.18936493]\n",
      " [-0.60331583]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.16630198 -0.722711  ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.2411778 1.2378017]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.2510234]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.210547, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.210547, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.1973932 -0.6421691]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2519618  -0.15130056]\n",
      " [ 0.08736683  1.6467121 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.18845734]\n",
      " [-0.60822016]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.1674459  -0.73099184]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.2494686 1.2460699]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.259234]], shape=(1, 1), dtype=float32)\n",
      "Epoch 80/100, Loss: 8.21054744720459\n",
      "Loss is :  tf.Tensor(8.148654, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.148654, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19672352 -0.6470559 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25180894 -0.15080725]\n",
      " [ 0.08806002  1.6489493 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.18755618]\n",
      " [-0.6131391 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.16858271 -0.7392874 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.2576983 1.2542778]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.2673826]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.086039, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.086039, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19605818 -0.65195   ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25165877 -0.15031634]\n",
      " [ 0.08875016  1.6512054 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.18666162]\n",
      " [-0.6180717 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.16971228 -0.7475962 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.265866  1.2624247]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.2754687]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(8.022702, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(8.022702, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19539724 -0.65685046]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25151128 -0.14982793]\n",
      " [ 0.08943712  1.65348   ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.1857738 ]\n",
      " [-0.62301695]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.1708345 -0.7559168]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.2739712 1.2705101]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.2834914]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.9586515, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.9586515, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19474077 -0.66175634]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2513664  -0.14934209]\n",
      " [ 0.09012078  1.6557728 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.1848929]\n",
      " [-0.6279739]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.17194927 -0.7642476 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.2820128 1.278533 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.29145]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.8938904, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.8938904, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19408885 -0.6666667 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25122416 -0.1488589 ]\n",
      " [ 0.09080103  1.6580832 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.18401904]\n",
      " [-0.6329416 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.17305645 -0.77258706]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.2899905 1.2864928]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.299344]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.8284235, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.8284235, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19344154 -0.67158055]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25108448 -0.14837846]\n",
      " [ 0.09147774  1.6604108 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.1831524 ]\n",
      " [-0.63791895]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.17415595 -0.78093356]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.2979034 1.294389 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3071724]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.7622576, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.7622576, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19279891 -0.676497  ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25094736 -0.14790085]\n",
      " [ 0.0921508   1.662755  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.18229312]\n",
      " [-0.6429049 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.17524764 -0.7892854 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3057507 1.3022207]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3149347]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.6953974, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.6953974, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19216104 -0.6814149 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25081274 -0.14742613]\n",
      " [ 0.09282009  1.6651155 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.18144132]\n",
      " [-0.6478983 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.1763314  -0.79764104]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3135319 1.3099873]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3226302]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.6278524, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.6278524, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19152799 -0.6863333 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25068063 -0.1469544 ]\n",
      " [ 0.09348547  1.6674914 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.18059716]\n",
      " [-0.65289813]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.17740712 -0.8059986 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3212461 1.3176881]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.330258]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.5596313, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.5596313, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19089983 -0.6912511 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.250551   -0.14648573]\n",
      " [ 0.09414686  1.6698825 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17976075]\n",
      " [-0.65790325]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.17847468 -0.81435645]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3288927 1.3253224]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3378177]], shape=(1, 1), dtype=float32)\n",
      "Epoch 90/100, Loss: 7.55963134765625\n",
      "Loss is :  tf.Tensor(7.4907417, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.4907417, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.19027664 -0.69616723]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2504238  -0.1460202 ]\n",
      " [ 0.09480412  1.6722881 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17893226]\n",
      " [-0.6629124 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.17953396 -0.8227127 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3364711 1.3328894]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3453084]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.421195, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.421195, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.18965848 -0.7010806 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.250299   -0.1455579 ]\n",
      " [ 0.09545714  1.6747074 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17811179]\n",
      " [-0.6679245 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.18058485 -0.8310656 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3439806 1.3403888]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3527296]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.3510027, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.3510027, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.18904541 -0.70599014]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2501766  -0.1450989 ]\n",
      " [ 0.09610581  1.67714   ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17729947]\n",
      " [-0.67293835]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.18162724 -0.8394132 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3514203 1.3478197]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3600806]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.2801743, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.2801743, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.18843752 -0.7108946 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.25005656 -0.14464328]\n",
      " [ 0.09675001  1.6795851 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17649542]\n",
      " [-0.6779526 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.18266103 -0.84775376]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3587898 1.3551815]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3673608]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.2087264, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.2087264, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.18783487 -0.7157929 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.24993885 -0.14419112]\n",
      " [ 0.09738964  1.682042  ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17569976]\n",
      " [-0.68296605]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.18368608 -0.8560853 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3660885 1.3624736]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3745695]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.136669, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.136669, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.18723753 -0.7206839 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.24982344 -0.14374249]\n",
      " [ 0.09802458  1.6845101 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17491259]\n",
      " [-0.6879775 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.18470228 -0.8644059 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3733156 1.3696954]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3817062]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(7.064019, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(7.064019, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.18664555 -0.7255664 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.24971029 -0.14329746]\n",
      " [ 0.09865472  1.6869886 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17413402]\n",
      " [-0.6929856 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.18570952 -0.8727135 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3804706 1.3768463]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.3887702]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(6.9907913, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(6.9907913, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.18605901 -0.7304392 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.2495994  -0.14285612]\n",
      " [ 0.09927996  1.6894768 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17336415]\n",
      " [-0.69798905]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.1867077  -0.88100624]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3875529 1.3839257]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.395761]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(6.9170012, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(6.9170012, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.18547799 -0.7353011 ]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.24949071 -0.14241853]\n",
      " [ 0.09990019  1.6919739 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17260309]\n",
      " [-0.70298654]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.18769673 -0.88928205]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.3945619 1.390933 ]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.402678]], shape=(1, 1), dtype=float32)\n",
      "Loss is :  tf.Tensor(6.8426666, shape=(), dtype=float32)\n",
      "Backward prop ongoing \n",
      "dz3 shape is  (10, 1)\n",
      "A_layer2 shape is  (10, 2)\n",
      "W3 shape is  (2, 1)\n",
      "mae is  tf.Tensor(6.8426666, shape=(), dtype=float32)\n",
      "Weights from first layer :  tf.Tensor([[-0.18490252 -0.74015087]], shape=(1, 2), dtype=float32)\n",
      "Weights from second layer :  tf.Tensor(\n",
      "[[-0.24938421 -0.14198478]\n",
      " [ 0.10051531  1.6944792 ]], shape=(2, 2), dtype=float32)\n",
      "Weights from third layer :  tf.Tensor(\n",
      "[[-0.17185092]\n",
      " [-0.7079767 ]], shape=(2, 1), dtype=float32)\n",
      "Biases from first layer :  tf.Tensor([[ 0.18867646 -0.89753896]], shape=(1, 2), dtype=float32)\n",
      "Biases from second layer :  tf.Tensor([[1.401497  1.3978677]], shape=(1, 2), dtype=float32)\n",
      "Biases from third layer :  tf.Tensor([[1.4095206]], shape=(1, 1), dtype=float32)\n",
      "Epoch 100/100, Loss: 6.8426666259765625\n"
     ]
    }
   ],
   "source": [
    "our_network3.train_network(x_prep,y_prep,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[1.2841169],\n",
       "       [2.1448314],\n",
       "       [3.0055463],\n",
       "       [3.866261 ],\n",
       "       [4.7269754],\n",
       "       [5.5876894],\n",
       "       [6.4484053],\n",
       "       [7.3091197],\n",
       "       [8.169834 ],\n",
       "       [9.030549 ]], dtype=float32)>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred4 = our_network3.get_prediction()\n",
    "y_pred4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
